{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adversarial Attacks\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/m12sl/dl-hse-2020/blob/master/06-adversarialx/adversarialx.ipynb)\n",
    "\n",
    "\n",
    "**Цели тетрадки**\n",
    "\n",
    "1. Познакомиться с двумя типами уязвимостей: perturbation-based и invariance-based.\n",
    "2. Проверить реализуемость атак.\n",
    "\n",
    "**План**\n",
    "\n",
    "1. Натренировать сеть для атаки.\n",
    "2. Реализовать два варианта perturbation-based атаки.\n",
    "3. Реализовать invariance-based атаку.\n",
    "4. Проверить устойчивость атак при реалистичных преобразованиях"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install requirements\n",
    "! pip install torchviz torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from collections import defaultdict\n",
    "\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.datasets import FashionMNIST\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "# имеет смысл добавить нормирование картинок\n",
    "\n",
    "train_dataset = FashionMNIST(\"./tmp\", train=True, download=True, transform=transform)\n",
    "val_dataset = FashionMNIST(\"./tmp\", train=False, download=True, transform=transform)\n",
    "train_loader = DataLoader(train_dataset, shuffle=True, batch_size=32)\n",
    "val_loader = DataLoader(val_dataset, shuffle=False, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "def train(model, optimizer, dataloader): \n",
    "    model.to(device)\n",
    "    model.train()\n",
    "    logs = defaultdict(list)\n",
    "    for x, y in tqdm(dataloader):\n",
    "        # todo: your code here        \n",
    "        x, y = x.to(device), y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(x)\n",
    "        loss = F.nll_loss(output, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        acc = torch.eq(torch.max(output, 1)[1], y).float().mean()\n",
    "\n",
    "        logs['acc'].append(acc.item())\n",
    "        logs['loss'].append(loss.item())\n",
    "    return logs\n",
    "\n",
    "def validate(model, dataloader):\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    logs = defaultdict(list)\n",
    "    for x, y in tqdm(dataloader):\n",
    "        # todo: your code here\n",
    "        with torch.no_grad():\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            output = model(x)\n",
    "            loss = F.nll_loss(output, y)\n",
    "            acc = torch.eq(torch.max(output, 1)[1], y).float().mean()\n",
    "        logs['acc'].append(acc.item())\n",
    "        logs['loss'].append(loss.item())\n",
    "    \n",
    "    return {k: [np.mean(v)] for k, v in logs.items()}\n",
    "\n",
    "def plot_logs(logs):\n",
    "    clear_output()\n",
    "    plt.figure()\n",
    "    plt.plot(logs['acc'], zorder=1)\n",
    "    plt.scatter(logs['steps'], logs['val_acc'], marker='+', s=180, c='orange', label='val', zorder=2)\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure()            \n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def train_model(model, optimizer, train_loader, val_loader, epochs=10):\n",
    "    logs = defaultdict(list)\n",
    "    for epoch in range(epochs):\n",
    "        train_logs = train(model, opt, train_loader)\n",
    "    \n",
    "        for k, v in train_logs.items():\n",
    "            logs[k].extend(v)\n",
    "\n",
    "        val_logs = validate(model, val_loader)\n",
    "        for k, v in val_logs.items():\n",
    "            logs[f'val_{k}'].extend(v)\n",
    "        logs['steps'].append(len(logs['loss']))\n",
    "\n",
    "        clear_output()\n",
    "        plot_logs(logs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Соберите какую-нибудь сверточную сеть и натренируйте ее**\n",
    "\n",
    "Для экономии времени можно остановиться на отметке 0.8+."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = nn.Sequential(\n",
    "    <your code here>\n",
    ")\n",
    "\n",
    "opt = torch.optim.SGD(cnn.parameters(), lr=0.01)\n",
    "train_model(cnn, opt, train_loader, val_loader, epochs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Посмотрим на примеры картинок\n",
    "def imshow(images):\n",
    "    img = torchvision.utils.make_grid(images).numpy()\n",
    "    plt.figure()\n",
    "    plt.imshow(np.transpose(img, (1, 2, 0)))\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "idx = [5, 10, 100, 0]\n",
    "imshow([val_dataset[_][0] for _ in idx])\n",
    "print([val_dataset[_][1] for _ in idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perturbation-based attack\n",
    "\n",
    "Имея white-box модель можно оптимизировать входные данные с помощью градиентного спуска.\n",
    "Предлагается попробовать два варианта perturbation-based атак:\n",
    "\n",
    "1. Наивный: $x = x + \\varepsilon \\nabla_x \\mathrm{loss(\\theta, x, y)}$\n",
    "\n",
    "2. Fast Gradient Sign: $x = x + \\varepsilon \\, \\mathrm{sign}[\\nabla_x \\mathrm{loss(\\theta, x, y)}]$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "def perturbation_attack_simple(inputs, labels, model, weight):    \n",
    "    # получите градиенты на картинку\n",
    "    # примените их к картинке\n",
    "    <your code>\n",
    "    return attacked, predicted\n",
    "\n",
    "attacked, preds = perturbation_attack(inputs, labels, copy(cnn), 10)\n",
    "print(labels)\n",
    "imshow(attacked)\n",
    "print(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perturbation_attack_sign(inputs, labels, model, weight):\n",
    "    # получите градиенты на картинку\n",
    "    # примените их к картинке\n",
    "    <your code>\n",
    "    return attacked, predicted\n",
    "\n",
    "\n",
    "attacked, preds = perturbation_attack_sign(inputs, labels, copy(cnn), 0.2)\n",
    "print(labels)\n",
    "imshow(corrupted_inputs.data)\n",
    "print(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_network_attack(net, dataloader, corrupt_function, weight):\n",
    "    class_correct = list(0. for i in range(10))\n",
    "    class_total = list(0. for i in range(10))\n",
    "    for data in tqdm(dataloader):\n",
    "        images, labels = data\n",
    "        images, _  = corrupt_function(images, labels, net, weight)\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        c = (predicted == labels).squeeze()\n",
    "        for i in range(4):\n",
    "            label = labels[i]\n",
    "            class_correct[label] += c[i]\n",
    "            class_total[label] += 1\n",
    "\n",
    "    print('Accuracy %d %% \\n' % (100. * sum(class_correct) / sum(class_total)))\n",
    "        \n",
    "    for i in range(10):\n",
    "        print('Accuracy of %2s : %2d %%' % (\n",
    "              i, 100. * class_correct[i] / class_total[i]))\n",
    "        \n",
    "evaluate_network_attack(cnn, val_loader, perturbation_attack, 10)\n",
    "evaluate_network_attack(cnn, val_loader, perturbation_attack_sign, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Invariance-based attack\n",
    "\n",
    "Пусть у нас есть два примера A и B разных классов (соответственно с разными логитами).\n",
    "Надо изменить B так, чтобы сеть выдавала такой же набор логитов, как и на A."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchviz\n",
    "import seaborn as sns\n",
    "\n",
    "def invariance_attack(A, B, model, iterations=1000, weight=0.01):\n",
    "    # получите target-логиты\n",
    "    # напишите подходящий лосс\n",
    "    # оптимизируйте картинку\n",
    "    \n",
    "    return attacked\n",
    "\n",
    "imshow([val_dataset[0][0], val_dataset[1][0]])\n",
    "A = val_dataset[0][0].unsqueeze(0)\n",
    "B = val_dataset[1][0].unsqueeze(0)\n",
    "\n",
    "x = invariance_attack(A, B, deepcopy(cnn))\n",
    "plt.imshow(x, cmap='gist_gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
