{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Autoencoders\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/m12sl/dl-hse-2020/blob/master/11-prob-models/autoencoders.ipynb)\n",
    "\n",
    "Занимаемся автоэнкодерами.\n",
    "\n",
    "<img src=\"https://github.com/m12sl/dl-hse-2020/raw/master/11-prob-models/img/encoder.png\" crossorigin=\"anonymous\"/>\n",
    "\n",
    "План:\n",
    "- написать несколько автоэнкодеров (AE, VAE) с разными размерностями внутреннних представлений.\n",
    "- сделать реконструкцию нескольких примеров\n",
    "- посмотреть на структуру внутреннего представления\n",
    "- сделать интерполяцию между несколькими примерами"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "import numpy as np\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from collections import defaultdict\n",
    "\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "# MNIST или FashionMNIST\n",
    "download_path = '/tmp'\n",
    "mnist_train = datasets.FashionMNIST(download_path, train=True, download=True, transform=transforms.ToTensor())\n",
    "mnist_val = datasets.FashionMNIST(download_path, train=False, download=True, transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=[6, 6])\n",
    "for i in range(4):\n",
    "    plt.subplot(2, 2, i + 1)\n",
    "    img, label = mnist_train[i]\n",
    "    plt.title(\"Label: {}\".format(label))\n",
    "    plt.imshow(img[0, ...], cmap='gray')\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для тренировки и отображения графиков возьмем наш предыдущий код и несколько его улучшим для произвольного числа метрик:\n",
    "\n",
    "1. Предлагается в коде модели написать метод `compute_all(batch)`, который будет вычислять предсказания, лосс и метрики\n",
    "2. Возвращать из него словарь `dict(loss=loss, metrics=dict(name=value))`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(log, name=None):\n",
    "    \"\"\"log is list of dictionaries like \n",
    "        [\n",
    "            {'train_step': 0, 'train_loss': 10.0, 'train_acc': 0.0}, \n",
    "            ...\n",
    "            {'train_step': 100, 'val_loss': 0.1, 'val_acc': 0.9},\n",
    "            ...\n",
    "        ]\n",
    "    \"\"\"\n",
    "    if name is None:\n",
    "        name='loss'\n",
    "    train_points, val_points = [], []\n",
    "    train_key = 'train_{}'.format(name)\n",
    "    val_key = 'val_{}'.format(name)\n",
    "\n",
    "    for entry in log:\n",
    "        if train_key in entry:\n",
    "            train_points.append((entry['train_step'], entry[train_key]))\n",
    "        if val_key in entry:\n",
    "            val_points.append((entry['train_step'], entry[val_key]))\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.title(name)\n",
    "    x, y = list(zip(*train_points))\n",
    "    plt.plot(x, y, label='train', zorder=1)\n",
    "    x, y = list(zip(*val_points))\n",
    "    plt.scatter(x, y, label='val', zorder=2, marker='+', s=180, c='orange')\n",
    "    \n",
    "    plt.legend(loc='best')\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def train_model(model, optimizer, train_dataset, val_dataset, batch_size=32, epochs=4):\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "    log = []\n",
    "    train_step = 0\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        for x, _ in tqdm(train_loader):\n",
    "            optimizer.zero_grad()\n",
    "            # возможно этот фрагмент вы захотите переписать\n",
    "            ret = model.compute_all(x)\n",
    "            loss = ret['loss']\n",
    "            #\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_metrics = {\"train_\" + key: value for key, value in ret['metrics'].items()}\n",
    "            log.append({**train_metrics, 'train_step': train_step})\n",
    "            train_step += 1\n",
    "\n",
    "        tmp = defaultdict(list)\n",
    "        model.eval()\n",
    "        for x, _ in tqdm(val_loader):\n",
    "            with torch.no_grad():\n",
    "                # не забудьте и этот\n",
    "                ret = model.compute_all(x)\n",
    "                # \n",
    "                for key, value in ret['metrics'].items():\n",
    "                    tmp[key].append(value)\n",
    "\n",
    "        metrics = tmp.keys()\n",
    "        val_metrics = {\"val_\" + key: np.mean(values) for key, values in tmp.items()}\n",
    "        log.append({**val_metrics, 'train_step': train_step})\n",
    "        \n",
    "        clear_output()\n",
    "        for m in metrics:\n",
    "            plot_history(log, name=m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обычный автоэнкодер\n",
    "\n",
    "**Задание 1. (0.2):** Сделайте автоэнкодер с несколькими линейными слоями, разделенными RELU с внутренним представлением размером 2.\n",
    "\n",
    "**Hint: для удобства добавьте методы compute_all/encode/decode**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AE(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # YOUR CODE HERE\n",
    "        self.encoder = ...\n",
    "        self.decoder = ...\n",
    "        \n",
    "    def compute_all(self, inp):\n",
    "        <your code here>\n",
    "        \n",
    "        return dict(\n",
    "            loss=loss,\n",
    "            metrics=dict(\n",
    "                # дополнительные метрики, какие хотите\n",
    "                loss=loss.item(),\n",
    "            )\n",
    "        )\n",
    "        \n",
    "\n",
    "ae = AE()\n",
    "opt = torch.optim.Adam(ae.parameters(), lr=1e-3)\n",
    "train_model(ae, opt, mnist_train, mnist_val, epochs=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание 1b (0.1):** Нарисуйте оригинал и восстановленную картинку"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reconstruction_plot(model, dataset):\n",
    "    plt.figure(figsize=[12, 3])\n",
    "    N = 10\n",
    "    idx = np.random.choice(len(dataset), size=N)\n",
    "    for i in range(N):\n",
    "        plt.subplot(2, N, i + 1)\n",
    "        img, label = dataset[idx[i]]\n",
    "        <your code here>\n",
    "        rec = ...\n",
    "\n",
    "        plt.title(\"id: {}\".format(idx[i]))\n",
    "        plt.imshow(img[0, ...], cmap='gray')\n",
    "        plt.axis('off')\n",
    "\n",
    "        plt.subplot(2, N, i + 1 + N)\n",
    "        plt.title('label: {}'.format(label))\n",
    "        plt.imshow(rec, cmap='gray')\n",
    "        plt.axis('off')\n",
    "\n",
    "    plt.subplots_adjust(wspace=0.03, hspace=0)\n",
    "    \n",
    "reconstruction_plot(ae, mnist_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание 1c (0.1)**: отобразите внутренние представления натренерованного AE на плоскости"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# посмотрим на внутренние представления\n",
    "def code_distribution(model, dataset):\n",
    "    N = 1000\n",
    "    idx = np.random.choice(len(dataset), size=N)\n",
    "    \n",
    "    <your code here>\n",
    "    x, y, colors = ...\n",
    "    \n",
    "    # если в x, y, colors лежат координаты и метки, то следующий код выведет график с легендой\n",
    "    cm=plt.cm.rainbow(np.linspace(0,1,10))\n",
    "    plt.figure(figsize=(12, 12))\n",
    "    plt.scatter(x, y, c=cm[np.array(colors)])\n",
    "    plt.grid()\n",
    "    plt.legend(handles=[mpatches.Patch(color=cm[i], label='{}'.format(i)) for i in range(10)])\n",
    "    plt.show()\n",
    "    \n",
    "code_distribution(ae, mnist_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Какие особенности вы видите на этой картинке?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание 1d (0.1)** Интерполяция! \n",
    "1. Выберете случайным образом несколько пар изображений, преобразуйте их в _коды_.\n",
    "2. Постройте линейную интерполяцию точек между ними (всего 10 точек, крайние -- это выбранные пары).\n",
    "3. Декодируйте коды в картинки.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_interpolations(model, dataset):\n",
    "    N = 10\n",
    "    idx = np.random.choice(len(dataset), size=N)\n",
    "    \n",
    "    # your code here\n",
    "    out = ...\n",
    "    # end of your code\n",
    "    # если out имеет размер [5, 10, 28, 28], следующий код нарисует таблицу с интерполяционными картинками\n",
    "    \n",
    "    fig, axes = plt.subplots(nrows=5, ncols=10, figsize=(14, 7),\n",
    "                             subplot_kw={'xticks': [], 'yticks': []})\n",
    "    \n",
    "    for i in range(50):\n",
    "        axes[i // 10, i % 10].imshow(out[i // 10, i % 10], cmap='gray')\n",
    "    \n",
    "\n",
    "plot_interpolations(ae, mnist_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Какие особенности вы видите на этих картинках?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Вариационный автоэнкодер (не Байесовский вывод)\n",
    "\n",
    "\n",
    "Предположим, мы хотим, чтобы `code` был распределен нормально (стандартное 2d распределение).\n",
    "Будем \n",
    "\n",
    "\n",
    "1. Как сделать одно распредление похожим на другое? Минимизировать KL-дивергеницю!\n",
    " \n",
    " $KL(q(x)||p(x)) = \\int q(x) \\log \\frac{q(x)}{p(x)}$\n",
    " \n",
    "2. Как сделать из `code` распределение, а не одну точку? Давайте сделаем из него распределение!\n",
    " \n",
    " $z = \\mu + \\varepsilon \\sigma$ где $code = [\\mu, \\sigma]$, а $\\varepsilon \\sim N(0, 1)$\n",
    " \n",
    "3. Мы можем не прописывать все распределение. Между модельными распредлениями дивергенцию можно прописать аналитически.\n",
    "\n",
    " $z \\sim N(\\mu, \\sigma)$\n",
    " \n",
    " $KL = \\sum\\limits_{i} \\mu^2 + \\sigma^2 - \\log \\sigma - 1$\n",
    " \n",
    " \n",
    "<img src=\"https://github.com/m12sl/dl-hse-2020/raw/master/11-prob-models/img/vae.png\" crossorigin=\"anonymous\"/>\n",
    " \n",
    " \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Что можно посмотреть про байесовский вывод?\n",
    "- [Лекция Ветрова DeepBayes2017. Модели с латентными переменными](https://youtu.be/7yLOF07Mv5I)\n",
    "- [Лекция Ветрова DeepBayes2017. Масштабируемые байесовские методы](https://youtu.be/if9bTlZOiO8) << тут про VAE\n",
    "- [Auto-Encoding Variational Bayes](https://arxiv.org/pdf/1312.6114.pdf)\n",
    "- [Tutorial on Variational Autoencoders](https://arxiv.org/pdf/1606.05908.pdf)\n",
    "- [blogpost](https://towardsdatascience.com/intuitively-understanding-variational-autoencoders-1bfe67eb5daf)\n",
    "- [KL дивергенция между двумя нормальными распределениями](https://stats.stackexchange.com/questions/7440/kl-divergence-between-two-univariate-gaussians)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание 2 (0.3)** Сделайте вариационный автоэнкодер с несколькими линейными слоями, разделенными RELU с внутренним представлением размером 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.encoder = ...\n",
    "        self.decoder = ...\n",
    "        \n",
    "    def compute_all(self, inp):\n",
    "        <your code here>\n",
    "        return dict(\n",
    "            loss=loss,\n",
    "            metrics=dict(\n",
    "                # любые метрики на ваш вкус\n",
    "                kld=kld.item(),\n",
    "                loss=loss.item(),\n",
    "            )\n",
    "        )\n",
    "vae = VAE()\n",
    "opt = torch.optim.Adam(vae.parameters(), lr=1e-3)\n",
    "train_model(vae, opt, mnist_train, mnist_val, epochs=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание 2b (0.2)** \n",
    "- Постройте реконструкционные примеры\n",
    "- Постройте распределение внутренних представлений\n",
    "- Постройте табличку с интерполяциями\n",
    "\n",
    "**Изменилось ли что-то по сравнению с обычным автоэнкодером?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstruction_plot(vae, mnist_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "code_distribution(vae, mnist_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_interpolations(ae, mnist_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание 3 (0.5+)** Увеличьте качество реконструкции (mae/mse-loss/тюнинг параметров или тренировка на пониженном LR, можно увеличить внутреннее представление). Постройте табличку с реконструкцией и интерполяцией."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Полезные применения (*)автоэнкодеров:\n",
    " - претрейн на неразмеченных данных\n",
    " - уменьшение размерности\n",
    " - полезные для других моделей представления\n",
    " - трактуемые внутренние представления\n",
    " - детектирование аномалий\n",
    " - denoising\n",
    " - манипуляции внутренними представлениями\n",
    " - синтез новых примеров\n",
    " - ...\n",
    "\n",
    "\n",
    "Для решения некоторых из этих задач не обязательно завязываться на encoder-decoder-архитектуру, посмотрите на i-RevNets (Invertible Reversible Networks):\n",
    "\n",
    "\n",
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
